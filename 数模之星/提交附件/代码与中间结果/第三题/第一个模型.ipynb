{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59d73fa-47cc-49fc-b5a4-25d59ad4fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold,RFECV\n",
    "from sklearn.model_selection import cross_validate,train_test_split,KFold\n",
    "from ITMO_FS.filters.univariate import f_ratio_measure,pearson_corr,spearman_corr,kendall_corr\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,PowerTransformer\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import r2_score,accuracy_score,roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ad452d-3f93-4faa-9882-7b8c4dd6b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(99)\n",
    "np.random.seed(99)\n",
    "random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb19b10e-44e0-49e5-b1e7-25c80135a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='finish_model.pkl', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        # torch.save(model.state_dict(), self.path)\n",
    "        torch.save(model, self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0f656a-68bf-4abe-9cda-0d099dd57869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulitiPrototypicalNet3(nn.Module):\n",
    "    def __init__(self,in_feature,num_class, embedding_dim,\n",
    "                 support_ratio = 0.6,query_ratio = 0.3,hidden1_dim = 256,hidden2_dim = 128,distance='euclidean'):\n",
    "        super(MulitiPrototypicalNet3, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.support_ratio = support_ratio\n",
    "        self.query_ratio = query_ratio\n",
    "        self.support_num = []\n",
    "        self.query_num = []\n",
    "        self.distance = distance\n",
    "        self.prototype = None\n",
    "        self.prototypes = []\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feature, out_features=hidden1_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=hidden1_dim, out_features=hidden2_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=hidden2_dim, out_features=embedding_dim),\n",
    "        )\n",
    "\n",
    "\n",
    "    def weights_init_(self):\n",
    "        for m in self.modules():\n",
    "            torch.nn.init.xavier_normal_(m.weight, gain=1, )\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def embedding(self, features):\n",
    "\n",
    "        result = self.feature_extraction(features)\n",
    "        return result\n",
    "\n",
    "    def forward(self, support_input, query_input):\n",
    "\n",
    "        support_embedding = self.embedding(support_input)\n",
    "        query_embedding = self.embedding(query_input)\n",
    "        support_size = support_embedding.shape[0]\n",
    "\n",
    "\n",
    "        class_meta_dict = {}\n",
    "\n",
    "        index_tmp = np.cumsum(self.support_num)\n",
    "\n",
    "\n",
    "        for i in range(0, self.num_class):\n",
    "            # i  0 , 1, 2, 3,\n",
    "            start_index = 0 if i == 0 else index_tmp[i-1]\n",
    "            end_index = index_tmp[i]\n",
    "            # class_meta_dict[i] = torch.sum(support_embedding[i * every_class_num:(i + 1) * every_class_num, :],\n",
    "            #                                dim=0) / self.support_num[i]\n",
    "\n",
    "            # print((start_index,end_index))\n",
    "\n",
    "            class_meta_dict[i] = torch.sum(support_embedding[start_index:end_index, :],\n",
    "                                           dim=0) / self.support_num[i]\n",
    "\n",
    "        class_meta_information = torch.zeros(size=[len(class_meta_dict), support_embedding.shape[1]])\n",
    "        for key, item in class_meta_dict.items():\n",
    "            class_meta_information[key, :] = class_meta_dict[key]\n",
    "\n",
    "        N_query = query_embedding.shape[0]\n",
    "        result = torch.zeros(size=[N_query, self.num_class])\n",
    "\n",
    "        self.prototype = class_meta_information\n",
    "        self.prototypes.append(class_meta_information.detach().numpy())\n",
    "\n",
    "        for i in range(0, N_query):\n",
    "            temp_value = query_embedding[i].repeat(self.num_class, 1)\n",
    "            dist_value = F.pairwise_distance(self.prototype, temp_value, p=2)\n",
    "            result[i] = -1 * dist_value\n",
    "        return result\n",
    "\n",
    "    def randomGenerate(self, X, Y):\n",
    "\n",
    "        support_index = []\n",
    "        for i in range(self.num_class):\n",
    "\n",
    "            support_index.extend(np.random.choice(np.where(Y == i)[0], self.support_num[i],\n",
    "                                                  replace=False))\n",
    "\n",
    "        support_index = np.array(support_index)\n",
    "        support_input = X[support_index, :]\n",
    "        support_label = Y[support_index]\n",
    "\n",
    "        query_index = []\n",
    "        for i in range(self.num_class):\n",
    "            query_index.extend(np.random.choice([index for index in np.where(Y == i)[0] if\n",
    "                                                 index not in support_index],\n",
    "                                                self.query_num[i], replace=False))\n",
    "        query_index = np.array(query_index)\n",
    "        query_input = X[query_index]\n",
    "        query_label = Y[query_index]\n",
    "\n",
    "        support_input = torch.tensor(support_input, dtype=torch.float)\n",
    "        query_input = torch.tensor(query_input, dtype=torch.float)\n",
    "        support_label = torch.tensor(support_label, dtype=torch.long)\n",
    "        query_label = torch.tensor(query_label, dtype=torch.long)\n",
    "\n",
    "        return support_input, query_input, support_label, query_label\n",
    "\n",
    "    \n",
    "    def fit(self,X_train,y_train,X_valid,y_valid,optimizer,criterion,patience,EPOCH):\n",
    "\n",
    "        for i in range(self.num_class):\n",
    "            cur_y_count = sum(y_train == i)\n",
    "            self.support_num.append(int(cur_y_count * self.support_ratio ))\n",
    "            self.query_num.append(int(cur_y_count * self.query_ratio))\n",
    "\n",
    "        # patience = patience  # 当验证集损失在连续20次训练周期中都没有得到降低时，停止模型训练，以防止模型过拟合\n",
    "        early_stopping = EarlyStopping(patience, verbose=True, path=\"finish_model_1.pkl\")        \n",
    "        \n",
    "        loss_list = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            self.train()\n",
    "            support_input, query_input, support_label, query_label = \\\n",
    "                self.randomGenerate(X_train,y_train)\n",
    "\n",
    "            output = self.forward(support_input, query_input)\n",
    "            loss = criterion(output, query_label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "        \n",
    "        \n",
    "            pre_valid_y, prob_valid_y = self.predict(X_valid)\n",
    "            auc = roc_auc_score(y_valid, prob_valid_y)\n",
    "            \n",
    "            \n",
    "            # print(\"Epoch: {:04d}\".format(epoch), \"acc:{:.4f}\".format(1 - error)      \n",
    "            \n",
    "            early_stopping(1-auc, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            \n",
    "            print(\"Epoch number:{},Current loss:{:.4f},Current accuracy:{:.4f}\\n\".format(epoch, loss.item(),auc))\n",
    "        \n",
    "        return loss_list\n",
    "    \n",
    "\n",
    "    def predict(self,X_test):\n",
    "\n",
    "        self.eval()\n",
    "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        X_embedding = self.embedding(X_test)\n",
    "        result = torch.zeros(size=[X_embedding.shape[0], self.num_class])\n",
    "        for i in range(0, X_embedding.shape[0]):\n",
    "\n",
    "            temp_value = X_embedding[i].repeat(self.num_class, 1)\n",
    "            dist_value = 0\n",
    "            if self.distance == 'euclidean':\n",
    "                dist_value = F.pairwise_distance(self.prototype, temp_value, p=2)\n",
    "            elif self.distance == 'cosine':\n",
    "                dist_value = torch.cosine_similarity(self.prototype, temp_value, dim=1)\n",
    "                dist_value = 1 - dist_value\n",
    "                  \n",
    "            result[i] = -1 * dist_value\n",
    "                  \n",
    "        result = F.softmax(result, dim=1)\n",
    "\n",
    "        pre_Y = torch.argmax(result, dim=1).detach().numpy().astype(int)\n",
    "        prob_Y = result[:,1].detach().numpy()\n",
    "        return pre_Y, prob_Y\n",
    "\n",
    "\n",
    "def protoNet_visualie2(model, X,Y,class_num, c, label):\n",
    "\n",
    "    prototypical = model.prototypes\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "    X_transform = model.embedding(X)\n",
    "    # pre_Y, prob_Y = model.predict(X)\n",
    "    print(X_transform.shape)\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(class_num):\n",
    "        cur_index = np.where(Y == i)[0]\n",
    "        cur_X = X_transform.detach().numpy()[cur_index, :]\n",
    "        plt.scatter(cur_X[:, 0], cur_X[:, 1], c=c[i], label=label[i])\n",
    "\n",
    "    plt.title(\"ProtoTypicalNet Output Visualization\", )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def miv(model, X):\n",
    "    model.eval()\n",
    "    miv = torch.ones(X.shape[1])\n",
    "    for i in range(X.shape[1]):\n",
    "\n",
    "        cur_X_1 = X.copy()\n",
    "        cur_X_2 = X.copy()\n",
    "\n",
    "        cur_X_1[:, i] = cur_X_1[:, i] + cur_X_1[:, i] * 0.1\n",
    "        cur_X_2[:, i] = cur_X_2[:, i] - cur_X_2[:, i] * 0.1\n",
    "\n",
    "        # cur_X_1 = np.log1p(cur_X_1)\n",
    "        # cur_X_2 = np.log1p(cur_X_2)\n",
    "        # std = StandardScaler()\n",
    "        # cur_X_1 = std.fit_transform(cur_X_1)\n",
    "        # cur_X_2 = std.fit_transform(cur_X_2)\n",
    "        cur_X_1 = torch.tensor(cur_X_1, dtype=torch.float)\n",
    "        cur_X_2 = torch.tensor(cur_X_2, dtype=torch.float)\n",
    "\n",
    "        cur_diff = torch.mean(model.embedding(cur_X_1) - model.embedding(cur_X_2), dim=1)\n",
    "        miv[i] = torch.mean(cur_diff, dim=0)\n",
    "\n",
    "    s = torch.abs(miv) / torch.sum(torch.abs(miv))\n",
    "    rank = torch.argsort(torch.abs(miv), dim=0, descending=True)\n",
    "    return rank, s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d619047-c467-45c6-9380-0b171b05b660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caco-2</th>\n",
       "      <th>CYP3A4</th>\n",
       "      <th>hERG</th>\n",
       "      <th>HOB</th>\n",
       "      <th>MN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMILES</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCC3)c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCCCC3)c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oc1ccc(cc1)[C@H]2Sc3cc(O)ccc3O[C@H]2c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oc1ccc2O[C@H]([C@@H](CC3CCCCC3)Sc2c1)c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oc1ccc2O[C@H]([C@@H](Cc3ccccc3)Sc2c1)c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Caco-2  CYP3A4  hERG  HOB  \\\n",
       "SMILES                                                                          \n",
       "Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCC3)c4ccc(OCCN5CC...       0       1     1    0   \n",
       "Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCCCC3)c4ccc(OCCN5...       0       1     1    0   \n",
       "Oc1ccc(cc1)[C@H]2Sc3cc(O)ccc3O[C@H]2c4ccc(OCCN5...       0       1     1    0   \n",
       "Oc1ccc2O[C@H]([C@@H](CC3CCCCC3)Sc2c1)c4ccc(OCCN...       0       1     1    0   \n",
       "Oc1ccc2O[C@H]([C@@H](Cc3ccccc3)Sc2c1)c4ccc(OCCN...       0       1     1    0   \n",
       "\n",
       "                                                    MN  \n",
       "SMILES                                                  \n",
       "Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCC3)c4ccc(OCCN5CC...   0  \n",
       "Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCCCC3)c4ccc(OCCN5...   0  \n",
       "Oc1ccc(cc1)[C@H]2Sc3cc(O)ccc3O[C@H]2c4ccc(OCCN5...   1  \n",
       "Oc1ccc2O[C@H]([C@@H](CC3CCCCC3)Sc2c1)c4ccc(OCCN...   0  \n",
       "Oc1ccc2O[C@H]([C@@H](Cc3ccccc3)Sc2c1)c4ccc(OCCN...   0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admet = pd.read_excel('../data/ADMET.xlsx',sheet_name=\"training\",engine='openpyxl',index_col=0,)\n",
    "admet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a91e4-e40b-40a9-9916-616a915259ee",
   "metadata": {},
   "source": [
    "############ 第一个  Caco-2 ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173cc77-b578-4f59-8a9a-179dec2b0c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4d7d7e-fca1-4c88-a9c3-7810aa39ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular_des_corr_del = pd.read_csv(\"../第一题/molecular_des_corr_del.csv\",index_col=0)\n",
    "all_data = molecular_des_corr_del.join(admet)\n",
    "X = all_data.iloc[:,:-5].values\n",
    "y = all_data.iloc[:,-5].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34020603-083a-42c8-9e2a-9afa462963a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y)    ### 1的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788584b6-645a-47fc-b4f7-7173f4ff3baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p1_ss.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.3, stratify=y,random_state=56)\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_valid = ss.transform(X_valid)\n",
    "joblib.dump(ss, 'p1_ss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "907965c6-1a5d-4845-a431-24622251f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/.conda/envs/shumo/lib/python3.7/site-packages/torch/autograd/__init__.py:149: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.137455).  Saving model ...\n",
      "Epoch number:0,Current loss:0.6884,Current accuracy:0.8625\n",
      "\n",
      "Validation loss decreased (0.137455 --> 0.107919).  Saving model ...\n",
      "Epoch number:1,Current loss:0.6758,Current accuracy:0.8921\n",
      "\n",
      "Validation loss decreased (0.107919 --> 0.101995).  Saving model ...\n",
      "Epoch number:2,Current loss:0.6465,Current accuracy:0.8980\n",
      "\n",
      "Validation loss decreased (0.101995 --> 0.099447).  Saving model ...\n",
      "Epoch number:3,Current loss:0.6116,Current accuracy:0.9006\n",
      "\n",
      "Validation loss decreased (0.099447 --> 0.097537).  Saving model ...\n",
      "Epoch number:4,Current loss:0.5649,Current accuracy:0.9025\n",
      "\n",
      "Validation loss decreased (0.097537 --> 0.094929).  Saving model ...\n",
      "Epoch number:5,Current loss:0.5381,Current accuracy:0.9051\n",
      "\n",
      "Validation loss decreased (0.094929 --> 0.093103).  Saving model ...\n",
      "Epoch number:6,Current loss:0.4855,Current accuracy:0.9069\n",
      "\n",
      "Validation loss decreased (0.093103 --> 0.090399).  Saving model ...\n",
      "Epoch number:7,Current loss:0.4700,Current accuracy:0.9096\n",
      "\n",
      "Validation loss decreased (0.090399 --> 0.088020).  Saving model ...\n",
      "Epoch number:8,Current loss:0.4044,Current accuracy:0.9120\n",
      "\n",
      "Validation loss decreased (0.088020 --> 0.086001).  Saving model ...\n",
      "Epoch number:9,Current loss:0.4357,Current accuracy:0.9140\n",
      "\n",
      "Validation loss decreased (0.086001 --> 0.082492).  Saving model ...\n",
      "Epoch number:10,Current loss:0.4585,Current accuracy:0.9175\n",
      "\n",
      "Validation loss decreased (0.082492 --> 0.079464).  Saving model ...\n",
      "Epoch number:11,Current loss:0.4127,Current accuracy:0.9205\n",
      "\n",
      "Validation loss decreased (0.079464 --> 0.076664).  Saving model ...\n",
      "Epoch number:12,Current loss:0.4063,Current accuracy:0.9233\n",
      "\n",
      "Validation loss decreased (0.076664 --> 0.074742).  Saving model ...\n",
      "Epoch number:13,Current loss:0.3559,Current accuracy:0.9253\n",
      "\n",
      "Validation loss decreased (0.074742 --> 0.071353).  Saving model ...\n",
      "Epoch number:14,Current loss:0.4053,Current accuracy:0.9286\n",
      "\n",
      "Validation loss decreased (0.071353 --> 0.068878).  Saving model ...\n",
      "Epoch number:15,Current loss:0.3541,Current accuracy:0.9311\n",
      "\n",
      "Validation loss decreased (0.068878 --> 0.065850).  Saving model ...\n",
      "Epoch number:16,Current loss:0.3322,Current accuracy:0.9342\n",
      "\n",
      "Validation loss decreased (0.065850 --> 0.064047).  Saving model ...\n",
      "Epoch number:17,Current loss:0.3082,Current accuracy:0.9360\n",
      "\n",
      "Validation loss decreased (0.064047 --> 0.061404).  Saving model ...\n",
      "Epoch number:18,Current loss:0.3202,Current accuracy:0.9386\n",
      "\n",
      "Validation loss decreased (0.061404 --> 0.058892).  Saving model ...\n",
      "Epoch number:19,Current loss:0.2806,Current accuracy:0.9411\n",
      "\n",
      "Validation loss decreased (0.058892 --> 0.055972).  Saving model ...\n",
      "Epoch number:20,Current loss:0.2392,Current accuracy:0.9440\n",
      "\n",
      "Validation loss decreased (0.055972 --> 0.053725).  Saving model ...\n",
      "Epoch number:21,Current loss:0.3104,Current accuracy:0.9463\n",
      "\n",
      "Validation loss decreased (0.053725 --> 0.051754).  Saving model ...\n",
      "Epoch number:22,Current loss:0.2909,Current accuracy:0.9482\n",
      "\n",
      "Validation loss decreased (0.051754 --> 0.049988).  Saving model ...\n",
      "Epoch number:23,Current loss:0.3092,Current accuracy:0.9500\n",
      "\n",
      "Validation loss decreased (0.049988 --> 0.048366).  Saving model ...\n",
      "Epoch number:24,Current loss:0.2696,Current accuracy:0.9516\n",
      "\n",
      "Validation loss decreased (0.048366 --> 0.047561).  Saving model ...\n",
      "Epoch number:25,Current loss:0.2606,Current accuracy:0.9524\n",
      "\n",
      "Validation loss decreased (0.047561 --> 0.046131).  Saving model ...\n",
      "Epoch number:26,Current loss:0.2496,Current accuracy:0.9539\n",
      "\n",
      "Validation loss decreased (0.046131 --> 0.044749).  Saving model ...\n",
      "Epoch number:27,Current loss:0.2755,Current accuracy:0.9553\n",
      "\n",
      "Validation loss decreased (0.044749 --> 0.043812).  Saving model ...\n",
      "Epoch number:28,Current loss:0.2360,Current accuracy:0.9562\n",
      "\n",
      "Validation loss decreased (0.043812 --> 0.043307).  Saving model ...\n",
      "Epoch number:29,Current loss:0.2477,Current accuracy:0.9567\n",
      "\n",
      "Validation loss decreased (0.043307 --> 0.042646).  Saving model ...\n",
      "Epoch number:30,Current loss:0.3100,Current accuracy:0.9574\n",
      "\n",
      "Validation loss decreased (0.042646 --> 0.041973).  Saving model ...\n",
      "Epoch number:31,Current loss:0.2464,Current accuracy:0.9580\n",
      "\n",
      "Validation loss decreased (0.041973 --> 0.041396).  Saving model ...\n",
      "Epoch number:32,Current loss:0.2296,Current accuracy:0.9586\n",
      "\n",
      "Validation loss decreased (0.041396 --> 0.040711).  Saving model ...\n",
      "Epoch number:33,Current loss:0.2370,Current accuracy:0.9593\n",
      "\n",
      "Validation loss decreased (0.040711 --> 0.040147).  Saving model ...\n",
      "Epoch number:34,Current loss:0.2093,Current accuracy:0.9599\n",
      "\n",
      "Validation loss decreased (0.040147 --> 0.040026).  Saving model ...\n",
      "Epoch number:35,Current loss:0.2620,Current accuracy:0.9600\n",
      "\n",
      "Validation loss decreased (0.040026 --> 0.039666).  Saving model ...\n",
      "Epoch number:36,Current loss:0.2490,Current accuracy:0.9603\n",
      "\n",
      "Validation loss decreased (0.039666 --> 0.039209).  Saving model ...\n",
      "Epoch number:37,Current loss:0.2393,Current accuracy:0.9608\n",
      "\n",
      "Validation loss decreased (0.039209 --> 0.038741).  Saving model ...\n",
      "Epoch number:38,Current loss:0.2197,Current accuracy:0.9613\n",
      "\n",
      "Validation loss decreased (0.038741 --> 0.038224).  Saving model ...\n",
      "Epoch number:39,Current loss:0.2516,Current accuracy:0.9618\n",
      "\n",
      "Validation loss decreased (0.038224 --> 0.037647).  Saving model ...\n",
      "Epoch number:40,Current loss:0.2419,Current accuracy:0.9624\n",
      "\n",
      "Validation loss decreased (0.037647 --> 0.037155).  Saving model ...\n",
      "Epoch number:41,Current loss:0.1995,Current accuracy:0.9628\n",
      "\n",
      "Validation loss decreased (0.037155 --> 0.036506).  Saving model ...\n",
      "Epoch number:42,Current loss:0.2343,Current accuracy:0.9635\n",
      "\n",
      "Validation loss decreased (0.036506 --> 0.035701).  Saving model ...\n",
      "Epoch number:43,Current loss:0.2097,Current accuracy:0.9643\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:44,Current loss:0.1817,Current accuracy:0.9643\n",
      "\n",
      "Validation loss decreased (0.035701 --> 0.035004).  Saving model ...\n",
      "Epoch number:45,Current loss:0.1928,Current accuracy:0.9650\n",
      "\n",
      "Validation loss decreased (0.035004 --> 0.034787).  Saving model ...\n",
      "Epoch number:46,Current loss:0.2167,Current accuracy:0.9652\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:47,Current loss:0.1805,Current accuracy:0.9647\n",
      "\n",
      "Validation loss decreased (0.034787 --> 0.034691).  Saving model ...\n",
      "Epoch number:48,Current loss:0.2105,Current accuracy:0.9653\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:49,Current loss:0.1847,Current accuracy:0.9652\n",
      "\n",
      "Validation loss decreased (0.034691 --> 0.034559).  Saving model ...\n",
      "Epoch number:50,Current loss:0.2345,Current accuracy:0.9654\n",
      "\n",
      "Validation loss decreased (0.034559 --> 0.034078).  Saving model ...\n",
      "Epoch number:51,Current loss:0.1632,Current accuracy:0.9659\n",
      "\n",
      "Validation loss decreased (0.034078 --> 0.033910).  Saving model ...\n",
      "Epoch number:52,Current loss:0.1652,Current accuracy:0.9661\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:53,Current loss:0.1891,Current accuracy:0.9660\n",
      "\n",
      "Validation loss decreased (0.033910 --> 0.033814).  Saving model ...\n",
      "Epoch number:54,Current loss:0.2134,Current accuracy:0.9662\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:55,Current loss:0.2066,Current accuracy:0.9660\n",
      "\n",
      "Validation loss decreased (0.033814 --> 0.033646).  Saving model ...\n",
      "Epoch number:56,Current loss:0.2102,Current accuracy:0.9664\n",
      "\n",
      "Validation loss decreased (0.033646 --> 0.033441).  Saving model ...\n",
      "Epoch number:57,Current loss:0.1702,Current accuracy:0.9666\n",
      "\n",
      "Validation loss decreased (0.033441 --> 0.033357).  Saving model ...\n",
      "Epoch number:58,Current loss:0.1969,Current accuracy:0.9666\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:59,Current loss:0.1646,Current accuracy:0.9662\n",
      "\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Epoch number:60,Current loss:0.1865,Current accuracy:0.9661\n",
      "\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Epoch number:61,Current loss:0.1728,Current accuracy:0.9666\n",
      "\n",
      "Validation loss decreased (0.033357 --> 0.033273).  Saving model ...\n",
      "Epoch number:62,Current loss:0.2063,Current accuracy:0.9667\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:63,Current loss:0.1659,Current accuracy:0.9666\n",
      "\n",
      "Validation loss decreased (0.033273 --> 0.033141).  Saving model ...\n",
      "Epoch number:64,Current loss:0.1589,Current accuracy:0.9669\n",
      "\n",
      "Validation loss decreased (0.033141 --> 0.032684).  Saving model ...\n",
      "Epoch number:65,Current loss:0.1633,Current accuracy:0.9673\n",
      "\n",
      "Validation loss decreased (0.032684 --> 0.031831).  Saving model ...\n",
      "Epoch number:66,Current loss:0.1860,Current accuracy:0.9682\n",
      "\n",
      "Validation loss decreased (0.031831 --> 0.031735).  Saving model ...\n",
      "Epoch number:67,Current loss:0.1769,Current accuracy:0.9683\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:68,Current loss:0.2096,Current accuracy:0.9682\n",
      "\n",
      "Validation loss decreased (0.031735 --> 0.031375).  Saving model ...\n",
      "Epoch number:69,Current loss:0.1847,Current accuracy:0.9686\n",
      "\n",
      "Validation loss decreased (0.031375 --> 0.031206).  Saving model ...\n",
      "Epoch number:70,Current loss:0.1556,Current accuracy:0.9688\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:71,Current loss:0.1494,Current accuracy:0.9679\n",
      "\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Epoch number:72,Current loss:0.1716,Current accuracy:0.9683\n",
      "\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Epoch number:73,Current loss:0.1518,Current accuracy:0.9681\n",
      "\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Epoch number:74,Current loss:0.1474,Current accuracy:0.9676\n",
      "\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Epoch number:75,Current loss:0.1761,Current accuracy:0.9672\n",
      "\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Epoch number:76,Current loss:0.1444,Current accuracy:0.9677\n",
      "\n",
      "EarlyStopping counter: 7 out of 50\n",
      "Epoch number:77,Current loss:0.1502,Current accuracy:0.9677\n",
      "\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Epoch number:78,Current loss:0.1447,Current accuracy:0.9685\n",
      "\n",
      "Validation loss decreased (0.031206 --> 0.030990).  Saving model ...\n",
      "Epoch number:79,Current loss:0.1319,Current accuracy:0.9690\n",
      "\n",
      "Validation loss decreased (0.030990 --> 0.030473).  Saving model ...\n",
      "Epoch number:80,Current loss:0.1366,Current accuracy:0.9695\n",
      "\n",
      "Validation loss decreased (0.030473 --> 0.029993).  Saving model ...\n",
      "Epoch number:81,Current loss:0.1599,Current accuracy:0.9700\n",
      "\n",
      "Validation loss decreased (0.029993 --> 0.029813).  Saving model ...\n",
      "Epoch number:82,Current loss:0.1590,Current accuracy:0.9702\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:83,Current loss:0.1613,Current accuracy:0.9700\n",
      "\n",
      "Validation loss decreased (0.029813 --> 0.029212).  Saving model ...\n",
      "Epoch number:84,Current loss:0.1335,Current accuracy:0.9708\n",
      "\n",
      "Validation loss decreased (0.029212 --> 0.029116).  Saving model ...\n",
      "Epoch number:85,Current loss:0.1784,Current accuracy:0.9709\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:86,Current loss:0.1464,Current accuracy:0.9703\n",
      "\n",
      "Validation loss decreased (0.029116 --> 0.028731).  Saving model ...\n",
      "Epoch number:87,Current loss:0.1465,Current accuracy:0.9713\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:88,Current loss:0.1763,Current accuracy:0.9710\n",
      "\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Epoch number:89,Current loss:0.1761,Current accuracy:0.9711\n",
      "\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Epoch number:90,Current loss:0.1458,Current accuracy:0.9711\n",
      "\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Epoch number:91,Current loss:0.1572,Current accuracy:0.9712\n",
      "\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Epoch number:92,Current loss:0.1264,Current accuracy:0.9708\n",
      "\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Epoch number:93,Current loss:0.1779,Current accuracy:0.9710\n",
      "\n",
      "EarlyStopping counter: 7 out of 50\n",
      "Epoch number:94,Current loss:0.1881,Current accuracy:0.9707\n",
      "\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Epoch number:95,Current loss:0.1120,Current accuracy:0.9707\n",
      "\n",
      "EarlyStopping counter: 9 out of 50\n",
      "Epoch number:96,Current loss:0.1594,Current accuracy:0.9706\n",
      "\n",
      "EarlyStopping counter: 10 out of 50\n",
      "Epoch number:97,Current loss:0.1259,Current accuracy:0.9706\n",
      "\n",
      "EarlyStopping counter: 11 out of 50\n",
      "Epoch number:98,Current loss:0.1085,Current accuracy:0.9705\n",
      "\n",
      "EarlyStopping counter: 12 out of 50\n",
      "Epoch number:99,Current loss:0.1483,Current accuracy:0.9706\n",
      "\n",
      "EarlyStopping counter: 13 out of 50\n",
      "Epoch number:100,Current loss:0.1164,Current accuracy:0.9705\n",
      "\n",
      "EarlyStopping counter: 14 out of 50\n",
      "Epoch number:101,Current loss:0.1593,Current accuracy:0.9702\n",
      "\n",
      "EarlyStopping counter: 15 out of 50\n",
      "Epoch number:102,Current loss:0.1211,Current accuracy:0.9701\n",
      "\n",
      "EarlyStopping counter: 16 out of 50\n",
      "Epoch number:103,Current loss:0.1247,Current accuracy:0.9701\n",
      "\n",
      "EarlyStopping counter: 17 out of 50\n",
      "Epoch number:104,Current loss:0.1405,Current accuracy:0.9702\n",
      "\n",
      "EarlyStopping counter: 18 out of 50\n",
      "Epoch number:105,Current loss:0.1341,Current accuracy:0.9705\n",
      "\n",
      "EarlyStopping counter: 19 out of 50\n",
      "Epoch number:106,Current loss:0.1609,Current accuracy:0.9703\n",
      "\n",
      "EarlyStopping counter: 20 out of 50\n",
      "Epoch number:107,Current loss:0.1576,Current accuracy:0.9702\n",
      "\n",
      "EarlyStopping counter: 21 out of 50\n",
      "Epoch number:108,Current loss:0.1310,Current accuracy:0.9700\n",
      "\n",
      "EarlyStopping counter: 22 out of 50\n",
      "Epoch number:109,Current loss:0.1522,Current accuracy:0.9701\n",
      "\n",
      "EarlyStopping counter: 23 out of 50\n",
      "Epoch number:110,Current loss:0.1514,Current accuracy:0.9706\n",
      "\n",
      "EarlyStopping counter: 24 out of 50\n",
      "Epoch number:111,Current loss:0.1060,Current accuracy:0.9705\n",
      "\n",
      "EarlyStopping counter: 25 out of 50\n",
      "Epoch number:112,Current loss:0.0763,Current accuracy:0.9708\n",
      "\n",
      "EarlyStopping counter: 26 out of 50\n",
      "Epoch number:113,Current loss:0.1352,Current accuracy:0.9711\n",
      "\n",
      "EarlyStopping counter: 27 out of 50\n",
      "Epoch number:114,Current loss:0.1129,Current accuracy:0.9712\n",
      "\n",
      "Validation loss decreased (0.028731 --> 0.028551).  Saving model ...\n",
      "Epoch number:115,Current loss:0.1616,Current accuracy:0.9714\n",
      "\n",
      "Validation loss decreased (0.028551 --> 0.028058).  Saving model ...\n",
      "Epoch number:116,Current loss:0.0972,Current accuracy:0.9719\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:117,Current loss:0.1420,Current accuracy:0.9719\n",
      "\n",
      "Validation loss decreased (0.028058 --> 0.027974).  Saving model ...\n",
      "Epoch number:118,Current loss:0.1319,Current accuracy:0.9720\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:119,Current loss:0.0893,Current accuracy:0.9719\n",
      "\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Epoch number:120,Current loss:0.1031,Current accuracy:0.9718\n",
      "\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Epoch number:121,Current loss:0.1013,Current accuracy:0.9713\n",
      "\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Epoch number:122,Current loss:0.1328,Current accuracy:0.9708\n",
      "\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Epoch number:123,Current loss:0.1940,Current accuracy:0.9699\n",
      "\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Epoch number:124,Current loss:0.1376,Current accuracy:0.9692\n",
      "\n",
      "EarlyStopping counter: 7 out of 50\n",
      "Epoch number:125,Current loss:0.1088,Current accuracy:0.9679\n",
      "\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Epoch number:126,Current loss:0.1410,Current accuracy:0.9682\n",
      "\n",
      "EarlyStopping counter: 9 out of 50\n",
      "Epoch number:127,Current loss:0.0968,Current accuracy:0.9692\n",
      "\n",
      "EarlyStopping counter: 10 out of 50\n",
      "Epoch number:128,Current loss:0.1277,Current accuracy:0.9697\n",
      "\n",
      "EarlyStopping counter: 11 out of 50\n",
      "Epoch number:129,Current loss:0.0794,Current accuracy:0.9697\n",
      "\n",
      "EarlyStopping counter: 12 out of 50\n",
      "Epoch number:130,Current loss:0.1117,Current accuracy:0.9707\n",
      "\n",
      "EarlyStopping counter: 13 out of 50\n",
      "Epoch number:131,Current loss:0.1006,Current accuracy:0.9712\n",
      "\n",
      "EarlyStopping counter: 14 out of 50\n",
      "Epoch number:132,Current loss:0.1298,Current accuracy:0.9717\n",
      "\n",
      "EarlyStopping counter: 15 out of 50\n",
      "Epoch number:133,Current loss:0.1005,Current accuracy:0.9720\n",
      "\n",
      "Validation loss decreased (0.027974 --> 0.027842).  Saving model ...\n",
      "Epoch number:134,Current loss:0.1020,Current accuracy:0.9722\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:135,Current loss:0.0915,Current accuracy:0.9721\n",
      "\n",
      "Validation loss decreased (0.027842 --> 0.027782).  Saving model ...\n",
      "Epoch number:136,Current loss:0.1202,Current accuracy:0.9722\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:137,Current loss:0.1446,Current accuracy:0.9721\n",
      "\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Epoch number:138,Current loss:0.0985,Current accuracy:0.9719\n",
      "\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Epoch number:139,Current loss:0.1169,Current accuracy:0.9717\n",
      "\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Epoch number:140,Current loss:0.1111,Current accuracy:0.9716\n",
      "\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Epoch number:141,Current loss:0.1139,Current accuracy:0.9718\n",
      "\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Epoch number:142,Current loss:0.0999,Current accuracy:0.9719\n",
      "\n",
      "EarlyStopping counter: 7 out of 50\n",
      "Epoch number:143,Current loss:0.0802,Current accuracy:0.9718\n",
      "\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Epoch number:144,Current loss:0.1258,Current accuracy:0.9720\n",
      "\n",
      "EarlyStopping counter: 9 out of 50\n",
      "Epoch number:145,Current loss:0.1071,Current accuracy:0.9719\n",
      "\n",
      "EarlyStopping counter: 10 out of 50\n",
      "Epoch number:146,Current loss:0.0856,Current accuracy:0.9712\n",
      "\n",
      "EarlyStopping counter: 11 out of 50\n",
      "Epoch number:147,Current loss:0.1013,Current accuracy:0.9713\n",
      "\n",
      "EarlyStopping counter: 12 out of 50\n",
      "Epoch number:148,Current loss:0.1186,Current accuracy:0.9707\n",
      "\n",
      "EarlyStopping counter: 13 out of 50\n",
      "Epoch number:149,Current loss:0.0823,Current accuracy:0.9705\n",
      "\n",
      "EarlyStopping counter: 14 out of 50\n",
      "Epoch number:150,Current loss:0.1053,Current accuracy:0.9707\n",
      "\n",
      "EarlyStopping counter: 15 out of 50\n",
      "Epoch number:151,Current loss:0.1224,Current accuracy:0.9710\n",
      "\n",
      "EarlyStopping counter: 16 out of 50\n",
      "Epoch number:152,Current loss:0.0696,Current accuracy:0.9711\n",
      "\n",
      "EarlyStopping counter: 17 out of 50\n",
      "Epoch number:153,Current loss:0.1002,Current accuracy:0.9712\n",
      "\n",
      "EarlyStopping counter: 18 out of 50\n",
      "Epoch number:154,Current loss:0.0857,Current accuracy:0.9711\n",
      "\n",
      "EarlyStopping counter: 19 out of 50\n",
      "Epoch number:155,Current loss:0.0735,Current accuracy:0.9711\n",
      "\n",
      "EarlyStopping counter: 20 out of 50\n",
      "Epoch number:156,Current loss:0.1248,Current accuracy:0.9707\n",
      "\n",
      "EarlyStopping counter: 21 out of 50\n",
      "Epoch number:157,Current loss:0.1166,Current accuracy:0.9707\n",
      "\n",
      "EarlyStopping counter: 22 out of 50\n",
      "Epoch number:158,Current loss:0.1085,Current accuracy:0.9705\n",
      "\n",
      "EarlyStopping counter: 23 out of 50\n",
      "Epoch number:159,Current loss:0.1284,Current accuracy:0.9703\n",
      "\n",
      "EarlyStopping counter: 24 out of 50\n",
      "Epoch number:160,Current loss:0.1061,Current accuracy:0.9696\n",
      "\n",
      "EarlyStopping counter: 25 out of 50\n",
      "Epoch number:161,Current loss:0.1001,Current accuracy:0.9685\n",
      "\n",
      "EarlyStopping counter: 26 out of 50\n",
      "Epoch number:162,Current loss:0.0912,Current accuracy:0.9678\n",
      "\n",
      "EarlyStopping counter: 27 out of 50\n",
      "Epoch number:163,Current loss:0.1017,Current accuracy:0.9672\n",
      "\n",
      "EarlyStopping counter: 28 out of 50\n",
      "Epoch number:164,Current loss:0.0873,Current accuracy:0.9674\n",
      "\n",
      "EarlyStopping counter: 29 out of 50\n",
      "Epoch number:165,Current loss:0.1053,Current accuracy:0.9678\n",
      "\n",
      "EarlyStopping counter: 30 out of 50\n",
      "Epoch number:166,Current loss:0.0779,Current accuracy:0.9683\n",
      "\n",
      "EarlyStopping counter: 31 out of 50\n",
      "Epoch number:167,Current loss:0.0711,Current accuracy:0.9695\n",
      "\n",
      "EarlyStopping counter: 32 out of 50\n",
      "Epoch number:168,Current loss:0.0898,Current accuracy:0.9705\n",
      "\n",
      "EarlyStopping counter: 33 out of 50\n",
      "Epoch number:169,Current loss:0.0915,Current accuracy:0.9711\n",
      "\n",
      "EarlyStopping counter: 34 out of 50\n",
      "Epoch number:170,Current loss:0.0733,Current accuracy:0.9714\n",
      "\n",
      "EarlyStopping counter: 35 out of 50\n",
      "Epoch number:171,Current loss:0.0683,Current accuracy:0.9715\n",
      "\n",
      "EarlyStopping counter: 36 out of 50\n",
      "Epoch number:172,Current loss:0.0789,Current accuracy:0.9719\n",
      "\n",
      "EarlyStopping counter: 37 out of 50\n",
      "Epoch number:173,Current loss:0.0704,Current accuracy:0.9713\n",
      "\n",
      "EarlyStopping counter: 38 out of 50\n",
      "Epoch number:174,Current loss:0.0785,Current accuracy:0.9713\n",
      "\n",
      "EarlyStopping counter: 39 out of 50\n",
      "Epoch number:175,Current loss:0.0875,Current accuracy:0.9710\n",
      "\n",
      "EarlyStopping counter: 40 out of 50\n",
      "Epoch number:176,Current loss:0.0816,Current accuracy:0.9705\n",
      "\n",
      "EarlyStopping counter: 41 out of 50\n",
      "Epoch number:177,Current loss:0.0831,Current accuracy:0.9703\n",
      "\n",
      "EarlyStopping counter: 42 out of 50\n",
      "Epoch number:178,Current loss:0.0793,Current accuracy:0.9700\n",
      "\n",
      "EarlyStopping counter: 43 out of 50\n",
      "Epoch number:179,Current loss:0.0599,Current accuracy:0.9696\n",
      "\n",
      "EarlyStopping counter: 44 out of 50\n",
      "Epoch number:180,Current loss:0.0777,Current accuracy:0.9691\n",
      "\n",
      "EarlyStopping counter: 45 out of 50\n",
      "Epoch number:181,Current loss:0.0871,Current accuracy:0.9701\n",
      "\n",
      "EarlyStopping counter: 46 out of 50\n",
      "Epoch number:182,Current loss:0.0639,Current accuracy:0.9704\n",
      "\n",
      "EarlyStopping counter: 47 out of 50\n",
      "Epoch number:183,Current loss:0.0619,Current accuracy:0.9708\n",
      "\n",
      "EarlyStopping counter: 48 out of 50\n",
      "Epoch number:184,Current loss:0.0727,Current accuracy:0.9716\n",
      "\n",
      "EarlyStopping counter: 49 out of 50\n",
      "Epoch number:185,Current loss:0.1062,Current accuracy:0.9720\n",
      "\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model = MulitiPrototypicalNet3(X_train.shape[1],2, 24,)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.fit(X_train,y_train,X_valid,y_valid,optimizer,criterion,50,500)\n",
    "pre_Y, prob_Y = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a84e55-141b-439f-8627-25ba53ca2280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:   0.9207419898819561\n",
      "auc:   0.9722182167748137\n"
     ]
    }
   ],
   "source": [
    "final_model1 = torch.load(\"./finish_model_1.pkl\")\n",
    "pre_valid_y_model1, prob_valid_y_model1 = final_model1.predict(X_valid)\n",
    "acc = accuracy_score(y_valid, pre_valid_y_model1)\n",
    "auc = roc_auc_score(y_valid,prob_valid_y_model1)\n",
    "print('acc:   ' + str(acc))\n",
    "print('auc:   ' + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f495a71f-c64b-4936-a512-53dc1d700e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9224283305227656"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.3, stratify=y,random_state=56)\n",
    "p2_ss = joblib.load(\"p2_ss.pkl\")\n",
    "pn_model2 = torch.load(\"./finish_model_1.pkl\")\n",
    "X_valid = p2_ss.transform(X_valid)\n",
    "accuracy_score(pn_model2.predict(X_valid)[0],y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd264dd-f9e0-4a1b-9b18-77e527eb89f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "045c1585-0f45-4fe1-9646-347efa7e8061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank,s = miv(final_model1,X_train)\n",
    "show_feature_num = 20\n",
    "\n",
    "f_importance = pd.DataFrame({\"feature\": molecular_des_corr_del.columns,\"importance\": s.detach().numpy()})\n",
    "f_importance = f_importance.sort_values(by=\"importance\", ascending=False)\n",
    "# print(f_importance)\n",
    "f_importance = f_importance[:show_feature_num]\n",
    "p = sns.barplot(x=\"importance\", y=\"feature\", data=f_importance,\n",
    "            order=f_importance[\"feature\"],orient=\"h\",)\n",
    "p.set_title('Caco-2 Feature importance')\n",
    "bar_fig = p.get_figure()\n",
    "bar_fig.savefig(\"png_Caco-2 Feature importance.png\",dpi=400)\n",
    "plt.show()\n",
    "f_importance.to_csv(\"Caco-2 Feature importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc62251c-03fb-4626-b428-34b2d9426616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 36,  68, 127,  81, 117,  75, 100,  99, 119,  59,  49,  63,  95, 120,\n",
       "        132,  21, 134, 109, 112, 124, 131, 136,   9,  88,  62, 123, 110,  54,\n",
       "         64,  90,   0, 135,  11,  32,  85,  22, 133, 121, 104,  24,  50,  15,\n",
       "         37, 126,  39,  26,  53, 101,   6,  25,  55,  80,  69,  79, 107,  61,\n",
       "         35, 122,  42,  44,  45,  87,  13,   7,  19,   1,  58,  52,   8,  84,\n",
       "         86,  73,  51,  17,  27,  65,  78,  66,  30,  74,  23,  12,  29,  71,\n",
       "        128,  89,  10,  70,  92, 108,  20,  67, 125,  82,  47,  83,  91,  93,\n",
       "         14,  97,  40, 105, 113, 106,   5,  48,   3,  33,  60,  28,  76, 116,\n",
       "         43,   4,  16, 115, 103,  38,  46,  57, 111, 118,  96,  56,  94,  41,\n",
       "         98,  18,  34,   2,  77, 102,  72, 130, 114,  31, 129])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c2c4d-7cdc-4bf9-a8b8-81907b8605ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32b6de1-016c-4798-80ac-d39ad93f8295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nAcid</th>\n",
       "      <th>ALogP</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>AMR</th>\n",
       "      <th>apol</th>\n",
       "      <th>naAromAtom</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>nHeavyAtom</th>\n",
       "      <th>nH</th>\n",
       "      <th>...</th>\n",
       "      <th>MW</th>\n",
       "      <th>WTPT-1</th>\n",
       "      <th>WTPT-2</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>WPOL</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMILES</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H]4O[C@H]3C(=C4c5ccc(O)cc5)c6ccc(O)cc6)cc2)c1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.8193</td>\n",
       "      <td>3.309852</td>\n",
       "      <td>177.6817</td>\n",
       "      <td>89.159790</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>73</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>598.166139</td>\n",
       "      <td>88.708522</td>\n",
       "      <td>2.062989</td>\n",
       "      <td>25.464529</td>\n",
       "      <td>21.942236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7421</td>\n",
       "      <td>70</td>\n",
       "      <td>2.526</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.7289</td>\n",
       "      <td>7.446895</td>\n",
       "      <td>125.0445</td>\n",
       "      <td>60.543860</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>384.136159</td>\n",
       "      <td>59.883849</td>\n",
       "      <td>2.064960</td>\n",
       "      <td>10.441277</td>\n",
       "      <td>10.441277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>49</td>\n",
       "      <td>3.681</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=O)O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.2303</td>\n",
       "      <td>4.974238</td>\n",
       "      <td>131.6880</td>\n",
       "      <td>64.439446</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>414.146724</td>\n",
       "      <td>63.762531</td>\n",
       "      <td>2.056856</td>\n",
       "      <td>13.254618</td>\n",
       "      <td>13.254618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2661</td>\n",
       "      <td>53</td>\n",
       "      <td>3.710</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.6387</td>\n",
       "      <td>6.962738</td>\n",
       "      <td>125.1723</td>\n",
       "      <td>60.434067</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>402.126737</td>\n",
       "      <td>61.734159</td>\n",
       "      <td>2.057805</td>\n",
       "      <td>12.992047</td>\n",
       "      <td>10.440839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2424</td>\n",
       "      <td>51</td>\n",
       "      <td>3.586</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.3834</td>\n",
       "      <td>11.447396</td>\n",
       "      <td>131.3467</td>\n",
       "      <td>62.532067</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>418.103894</td>\n",
       "      <td>61.734159</td>\n",
       "      <td>2.057805</td>\n",
       "      <td>12.992047</td>\n",
       "      <td>7.310754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2424</td>\n",
       "      <td>51</td>\n",
       "      <td>3.978</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 729 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    nAcid   ALogP     ALogp2  \\\n",
       "SMILES                                                                         \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...      0  1.8193   3.309852   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4      1  2.7289   7.446895   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...      1  2.2303   4.974238   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...      1  2.6387   6.962738   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...      1  3.3834  11.447396   \n",
       "\n",
       "                                                         AMR       apol  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  177.6817  89.159790   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  125.0445  60.543860   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  131.6880  64.439446   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  125.1723  60.434067   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  131.3467  62.532067   \n",
       "\n",
       "                                                    naAromAtom  nAromBond  \\\n",
       "SMILES                                                                      \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...          24         24   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4          18         18   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...          18         18   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...          18         18   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...          18         18   \n",
       "\n",
       "                                                    nAtom  nHeavyAtom  nH  \\\n",
       "SMILES                                                                      \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...     73          43  30   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4     49          29  20   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...     53          31  22   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...     49          30  19   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...     49          30  19   \n",
       "\n",
       "                                                    ...          MW  \\\n",
       "SMILES                                              ...               \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  ...  598.166139   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  ...  384.136159   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  ...  414.146724   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  ...  402.126737   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  ...  418.103894   \n",
       "\n",
       "                                                       WTPT-1    WTPT-2  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  88.708522  2.062989   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  59.883849  2.064960   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  63.762531  2.056856   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  61.734159  2.057805   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  61.734159  2.057805   \n",
       "\n",
       "                                                       WTPT-3     WTPT-4  \\\n",
       "SMILES                                                                     \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  25.464529  21.942236   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  10.441277  10.441277   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  13.254618  13.254618   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  12.992047  10.440839   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  12.992047   7.310754   \n",
       "\n",
       "                                                    WTPT-5  WPATH  WPOL  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...     0.0   7421    70   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4     0.0   2217    49   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...     0.0   2661    53   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...     0.0   2424    51   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...     0.0   2424    51   \n",
       "\n",
       "                                                    XLogP  Zagreb  \n",
       "SMILES                                                             \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  2.526     236  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  3.681     152  \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  3.710     162  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  3.586     158  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  3.978     158  \n",
       "\n",
       "[5 rows x 729 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecular_test = pd.read_excel('../data/Molecular_Descriptor.xlsx',sheet_name=\"test\",engine='openpyxl',index_col=0,)\n",
    "molecular_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d65a6a-e9f2-4822-928b-b5655cec809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_coulmns = molecular_des_corr_del.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21cc2373-1b4f-4d0f-aeb4-a0cd41c27c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  3.        , -1.90206504, ...,  8.        ,\n",
       "         3.30985249,  6.07537   ],\n",
       "       [ 2.        ,  0.        ,  0.        , ...,  4.        ,\n",
       "         7.44689521,  4.99117   ],\n",
       "       [ 2.        ,  0.        ,  0.        , ...,  5.        ,\n",
       "         4.97423809,  4.99977   ],\n",
       "       ...,\n",
       "       [ 5.        ,  1.        ,  0.        , ...,  6.        ,\n",
       "         3.57361216,  5.08198   ],\n",
       "       [ 7.        ,  1.        ,  0.        , ...,  7.        ,\n",
       "         0.73667889,  6.19927   ],\n",
       "       [ 8.        ,  1.        ,  0.        , ...,  3.        ,\n",
       "         7.74341929,  6.50928   ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test = molecular_test.loc[:,final_test_coulmns].values\n",
    "final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36da7229-b8f2-4424-9012-d461b9b32a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "p2_ss = joblib.load(\"p2_ss.pkl\")\n",
    "pn_model2 = torch.load(\"./finish_model_1.pkl\")\n",
    "final_test = p2_ss.transform(final_test)\n",
    "for i in pn_model2.predict(final_test)[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230724be-bfc3-4eaa-8118-816d4128c368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92480fc-bf25-416a-9b3a-06ef1f5f067c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3cde76-f3e8-4c5a-b11a-40ade5b3422c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e758ad9-3506-435a-931a-1f4a9125bbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0eada8-5275-4c9c-b723-ba5469f7d23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59d73fa-47cc-49fc-b5a4-25d59ad4fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold,RFECV\n",
    "from sklearn.model_selection import cross_validate,train_test_split,KFold\n",
    "from ITMO_FS.filters.univariate import f_ratio_measure,pearson_corr,spearman_corr,kendall_corr\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,PowerTransformer\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import r2_score,accuracy_score,roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ad452d-3f93-4faa-9882-7b8c4dd6b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(999)\n",
    "np.random.seed(999)\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3059a4b-647a-4163-a0b1-7bf93f420ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='finish_model.pkl', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        # torch.save(model.state_dict(), self.path)\n",
    "        torch.save(model, self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0f656a-68bf-4abe-9cda-0d099dd57869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulitiPrototypicalNet3(nn.Module):\n",
    "    def __init__(self,in_feature,num_class, embedding_dim,\n",
    "                 support_ratio = 0.6,query_ratio = 0.3,hidden1_dim = 1024,hidden2_dim = 256,distance='euclidean'):\n",
    "        super(MulitiPrototypicalNet3, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.support_ratio = support_ratio\n",
    "        self.query_ratio = query_ratio\n",
    "        self.support_num = []\n",
    "        self.query_num = []\n",
    "        self.distance = distance\n",
    "        self.prototype = None\n",
    "        self.prototypes = []\n",
    "        \n",
    "        self.loss=[]\n",
    "        self.acc=[]\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feature, out_features=hidden1_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=hidden1_dim, out_features=hidden2_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=hidden2_dim, out_features=embedding_dim),\n",
    "        )\n",
    "\n",
    "\n",
    "    def weights_init_(self):\n",
    "        for m in self.modules():\n",
    "            torch.nn.init.xavier_normal_(m.weight, gain=1, )\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def embedding(self, features):\n",
    "\n",
    "        result = self.feature_extraction(features)\n",
    "        return result\n",
    "\n",
    "    def forward(self, support_input, query_input):\n",
    "\n",
    "        support_embedding = self.embedding(support_input)\n",
    "        query_embedding = self.embedding(query_input)\n",
    "        support_size = support_embedding.shape[0]\n",
    "\n",
    "\n",
    "        class_meta_dict = {}\n",
    "\n",
    "        index_tmp = np.cumsum(self.support_num)\n",
    "\n",
    "\n",
    "        for i in range(0, self.num_class):\n",
    "            # i  0 , 1, 2, 3,\n",
    "            start_index = 0 if i == 0 else index_tmp[i-1]\n",
    "            end_index = index_tmp[i]\n",
    "            # class_meta_dict[i] = torch.sum(support_embedding[i * every_class_num:(i + 1) * every_class_num, :],\n",
    "            #                                dim=0) / self.support_num[i]\n",
    "\n",
    "            # print((start_index,end_index))\n",
    "\n",
    "            class_meta_dict[i] = torch.sum(support_embedding[start_index:end_index, :],\n",
    "                                           dim=0) / self.support_num[i]\n",
    "\n",
    "        class_meta_information = torch.zeros(size=[len(class_meta_dict), support_embedding.shape[1]])\n",
    "        for key, item in class_meta_dict.items():\n",
    "            class_meta_information[key, :] = class_meta_dict[key]\n",
    "\n",
    "        N_query = query_embedding.shape[0]\n",
    "        result = torch.zeros(size=[N_query, self.num_class])\n",
    "\n",
    "        self.prototype = class_meta_information\n",
    "        self.prototypes.append(class_meta_information.detach().numpy())\n",
    "\n",
    "        for i in range(0, N_query):\n",
    "            temp_value = query_embedding[i].repeat(self.num_class, 1)\n",
    "            dist_value = F.pairwise_distance(self.prototype, temp_value, p=2)\n",
    "            result[i] = -1 * dist_value\n",
    "        return result\n",
    "\n",
    "    def randomGenerate(self, X, Y):\n",
    "\n",
    "        support_index = []\n",
    "        for i in range(self.num_class):\n",
    "\n",
    "            support_index.extend(np.random.choice(np.where(Y == i)[0], self.support_num[i],\n",
    "                                                  replace=False))\n",
    "\n",
    "        support_index = np.array(support_index)\n",
    "        support_input = X[support_index, :]\n",
    "        support_label = Y[support_index]\n",
    "\n",
    "        query_index = []\n",
    "        for i in range(self.num_class):\n",
    "            query_index.extend(np.random.choice([index for index in np.where(Y == i)[0] if\n",
    "                                                 index not in support_index],\n",
    "                                                self.query_num[i], replace=False))\n",
    "        query_index = np.array(query_index)\n",
    "        query_input = X[query_index]\n",
    "        query_label = Y[query_index]\n",
    "\n",
    "        support_input = torch.tensor(support_input, dtype=torch.float)\n",
    "        query_input = torch.tensor(query_input, dtype=torch.float)\n",
    "        support_label = torch.tensor(support_label, dtype=torch.long)\n",
    "        query_label = torch.tensor(query_label, dtype=torch.long)\n",
    "\n",
    "        return support_input, query_input, support_label, query_label\n",
    "\n",
    "\n",
    "    \n",
    "    def fit(self,X_train,y_train,X_valid,y_valid,optimizer,criterion,patience,EPOCH):\n",
    "\n",
    "        for i in range(self.num_class):\n",
    "            cur_y_count = sum(y_train == i)\n",
    "            self.support_num.append(int(cur_y_count * self.support_ratio ))\n",
    "            self.query_num.append(int(cur_y_count * self.query_ratio))\n",
    "\n",
    "        # patience = patience  # 当验证集损失在连续20次训练周期中都没有得到降低时，停止模型训练，以防止模型过拟合\n",
    "        early_stopping = EarlyStopping(patience, verbose=True, path=\"finish_model_2.pkl\")        \n",
    "        \n",
    "        loss_list = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            self.train()\n",
    "            support_input, query_input, support_label, query_label = \\\n",
    "                self.randomGenerate(X_train,y_train)\n",
    "\n",
    "            output = self.forward(support_input, query_input)\n",
    "            loss = criterion(output, query_label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "        \n",
    "        \n",
    "            pre_valid_y, prob_valid_y = self.predict(X_valid)\n",
    "            auc = roc_auc_score(y_valid, prob_valid_y)\n",
    "           \n",
    "            \n",
    "            # print(\"Epoch: {:04d}\".format(epoch), \"acc:{:.4f}\".format(1 - error)      \n",
    "            \n",
    "            early_stopping(1-auc, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            \n",
    "            self.acc.append(auc)\n",
    "            self.loss.append(loss.item())\n",
    "            \n",
    "            \n",
    "            print(\"Epoch number:{},Current loss:{:.4f},Current accuracy:{:.4f}\\n\".format(epoch, loss.item(),auc))\n",
    "        \n",
    "        return loss_list\n",
    "        \n",
    "    \n",
    "    def predict(self,X_test):\n",
    "\n",
    "        self.eval()\n",
    "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        X_embedding = self.embedding(X_test)\n",
    "        result = torch.zeros(size=[X_embedding.shape[0], self.num_class])\n",
    "        for i in range(0, X_embedding.shape[0]):\n",
    "\n",
    "            temp_value = X_embedding[i].repeat(self.num_class, 1)\n",
    "            dist_value = 0\n",
    "            if self.distance == 'euclidean':\n",
    "                dist_value = F.pairwise_distance(self.prototype, temp_value, p=2)\n",
    "            elif self.distance == 'cosine':\n",
    "                dist_value = torch.cosine_similarity(self.prototype, temp_value, dim=1)\n",
    "                dist_value = 1 - dist_value\n",
    "                  \n",
    "            result[i] = -1 * dist_value\n",
    "                  \n",
    "        result = F.softmax(result, dim=1)\n",
    "\n",
    "        pre_Y = torch.argmax(result, dim=1).detach().numpy().astype(int)\n",
    "        prob_Y = result[:,1].detach().numpy()\n",
    "        return pre_Y, prob_Y\n",
    "    \n",
    "\n",
    "\n",
    "def protoNet_visualie2(model, X,Y,class_num, c, label):\n",
    "\n",
    "    prototypical = model.prototypes\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "    X_transform = model.embedding(X)\n",
    "    # pre_Y, prob_Y = model.predict(X)\n",
    "    print(X_transform.shape)\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(class_num):\n",
    "        cur_index = np.where(Y == i)[0]\n",
    "        cur_X = X_transform.detach().numpy()[cur_index, :]\n",
    "        plt.scatter(cur_X[:, 0], cur_X[:, 1], c=c[i], label=label[i])\n",
    "\n",
    "    plt.title(\"ProtoTypicalNet Output Visualization\", )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def miv(model, X):\n",
    "    model.eval()\n",
    "    miv = torch.ones(X.shape[1])\n",
    "    for i in range(X.shape[1]):\n",
    "\n",
    "        cur_X_1 = X.copy()\n",
    "        cur_X_2 = X.copy()\n",
    "\n",
    "        cur_X_1[:, i] = cur_X_1[:, i] + cur_X_1[:, i] * 0.1\n",
    "        cur_X_2[:, i] = cur_X_2[:, i] - cur_X_2[:, i] * 0.1\n",
    "\n",
    "        # cur_X_1 = np.log1p(cur_X_1)\n",
    "        # cur_X_2 = np.log1p(cur_X_2)\n",
    "        # std = StandardScaler()\n",
    "        # cur_X_1 = std.fit_transform(cur_X_1)\n",
    "        # cur_X_2 = std.fit_transform(cur_X_2)\n",
    "        cur_X_1 = torch.tensor(cur_X_1, dtype=torch.float)\n",
    "        cur_X_2 = torch.tensor(cur_X_2, dtype=torch.float)\n",
    "\n",
    "        cur_diff = torch.mean(model.embedding(cur_X_1) - model.embedding(cur_X_2), dim=1)\n",
    "        miv[i] = torch.mean(cur_diff, dim=0)\n",
    "\n",
    "    s = torch.abs(miv) / torch.sum(torch.abs(miv))\n",
    "    rank = torch.argsort(torch.abs(miv), dim=0, descending=True)\n",
    "    return rank, s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b49403f-0e2f-4f76-91af-135c021a1676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caco-2</th>\n",
       "      <th>CYP3A4</th>\n",
       "      <th>hERG</th>\n",
       "      <th>HOB</th>\n",
       "      <th>MN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMILES</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCC3)c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCCCC3)c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oc1ccc(cc1)[C@H]2Sc3cc(O)ccc3O[C@H]2c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oc1ccc2O[C@H]([C@@H](CC3CCCCC3)Sc2c1)c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oc1ccc2O[C@H]([C@@H](Cc3ccccc3)Sc2c1)c4ccc(OCCN5CCCCC5)cc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Caco-2  CYP3A4  hERG  HOB  \\\n",
       "SMILES                                                                          \n",
       "Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCC3)c4ccc(OCCN5CC...       0       1     1    0   \n",
       "Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCCCC3)c4ccc(OCCN5...       0       1     1    0   \n",
       "Oc1ccc(cc1)[C@H]2Sc3cc(O)ccc3O[C@H]2c4ccc(OCCN5...       0       1     1    0   \n",
       "Oc1ccc2O[C@H]([C@@H](CC3CCCCC3)Sc2c1)c4ccc(OCCN...       0       1     1    0   \n",
       "Oc1ccc2O[C@H]([C@@H](Cc3ccccc3)Sc2c1)c4ccc(OCCN...       0       1     1    0   \n",
       "\n",
       "                                                    MN  \n",
       "SMILES                                                  \n",
       "Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCC3)c4ccc(OCCN5CC...   0  \n",
       "Oc1ccc2O[C@H]([C@H](Sc2c1)C3CCCCCC3)c4ccc(OCCN5...   0  \n",
       "Oc1ccc(cc1)[C@H]2Sc3cc(O)ccc3O[C@H]2c4ccc(OCCN5...   1  \n",
       "Oc1ccc2O[C@H]([C@@H](CC3CCCCC3)Sc2c1)c4ccc(OCCN...   0  \n",
       "Oc1ccc2O[C@H]([C@@H](Cc3ccccc3)Sc2c1)c4ccc(OCCN...   0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admet = pd.read_excel('../data/ADMET.xlsx',sheet_name=\"training\",engine='openpyxl',index_col=0,)\n",
    "admet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a91e4-e40b-40a9-9916-616a915259ee",
   "metadata": {},
   "source": [
    "############ 第二个  CYP3A4 ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b4d7d7e-fca1-4c88-a9c3-7810aa39ad5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1974, 137)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecular_des_corr_del = pd.read_csv(\"../第一题/molecular_des_corr_del.csv\",index_col=0)\n",
    "all_data = molecular_des_corr_del.join(admet)\n",
    "X = all_data.iloc[:,:-5].values\n",
    "y = all_data.iloc[:,-4].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34020603-083a-42c8-9e2a-9afa462963a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1461"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y)    ### 1的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "788584b6-645a-47fc-b4f7-7173f4ff3baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p2_ss.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.3, stratify=y,random_state=56)\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_valid = ss.transform(X_valid)\n",
    "joblib.dump(ss, 'p2_ss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "907965c6-1a5d-4845-a431-24622251f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.065897).  Saving model ...\n",
      "Epoch number:0,Current loss:0.6843,Current accuracy:0.9341\n",
      "\n",
      "Validation loss decreased (0.065897 --> 0.058797).  Saving model ...\n",
      "Epoch number:1,Current loss:0.5398,Current accuracy:0.9412\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:2,Current loss:0.3800,Current accuracy:0.9391\n",
      "\n",
      "Validation loss decreased (0.058797 --> 0.055897).  Saving model ...\n",
      "Epoch number:3,Current loss:0.3341,Current accuracy:0.9441\n",
      "\n",
      "Validation loss decreased (0.055897 --> 0.049330).  Saving model ...\n",
      "Epoch number:4,Current loss:0.3184,Current accuracy:0.9507\n",
      "\n",
      "Validation loss decreased (0.049330 --> 0.044197).  Saving model ...\n",
      "Epoch number:5,Current loss:0.2727,Current accuracy:0.9558\n",
      "\n",
      "Validation loss decreased (0.044197 --> 0.041683).  Saving model ...\n",
      "Epoch number:6,Current loss:0.2839,Current accuracy:0.9583\n",
      "\n",
      "Validation loss decreased (0.041683 --> 0.038207).  Saving model ...\n",
      "Epoch number:7,Current loss:0.2397,Current accuracy:0.9618\n",
      "\n",
      "Validation loss decreased (0.038207 --> 0.037216).  Saving model ...\n",
      "Epoch number:8,Current loss:0.2328,Current accuracy:0.9628\n",
      "\n",
      "Validation loss decreased (0.037216 --> 0.036713).  Saving model ...\n",
      "Epoch number:9,Current loss:0.2715,Current accuracy:0.9633\n",
      "\n",
      "Validation loss decreased (0.036713 --> 0.036121).  Saving model ...\n",
      "Epoch number:10,Current loss:0.2367,Current accuracy:0.9639\n",
      "\n",
      "Validation loss decreased (0.036121 --> 0.034893).  Saving model ...\n",
      "Epoch number:11,Current loss:0.2001,Current accuracy:0.9651\n",
      "\n",
      "Validation loss decreased (0.034893 --> 0.033518).  Saving model ...\n",
      "Epoch number:12,Current loss:0.1985,Current accuracy:0.9665\n",
      "\n",
      "Validation loss decreased (0.033518 --> 0.031092).  Saving model ...\n",
      "Epoch number:13,Current loss:0.2017,Current accuracy:0.9689\n",
      "\n",
      "Validation loss decreased (0.031092 --> 0.030086).  Saving model ...\n",
      "Epoch number:14,Current loss:0.2181,Current accuracy:0.9699\n",
      "\n",
      "Validation loss decreased (0.030086 --> 0.029420).  Saving model ...\n",
      "Epoch number:15,Current loss:0.2063,Current accuracy:0.9706\n",
      "\n",
      "Validation loss decreased (0.029420 --> 0.027320).  Saving model ...\n",
      "Epoch number:16,Current loss:0.1577,Current accuracy:0.9727\n",
      "\n",
      "Validation loss decreased (0.027320 --> 0.026714).  Saving model ...\n",
      "Epoch number:17,Current loss:0.1786,Current accuracy:0.9733\n",
      "\n",
      "Validation loss decreased (0.026714 --> 0.025205).  Saving model ...\n",
      "Epoch number:18,Current loss:0.1411,Current accuracy:0.9748\n",
      "\n",
      "Validation loss decreased (0.025205 --> 0.024317).  Saving model ...\n",
      "Epoch number:19,Current loss:0.1697,Current accuracy:0.9757\n",
      "\n",
      "Validation loss decreased (0.024317 --> 0.023563).  Saving model ...\n",
      "Epoch number:20,Current loss:0.2076,Current accuracy:0.9764\n",
      "\n",
      "Validation loss decreased (0.023563 --> 0.021788).  Saving model ...\n",
      "Epoch number:21,Current loss:0.1644,Current accuracy:0.9782\n",
      "\n",
      "Validation loss decreased (0.021788 --> 0.021403).  Saving model ...\n",
      "Epoch number:22,Current loss:0.1280,Current accuracy:0.9786\n",
      "\n",
      "Validation loss decreased (0.021403 --> 0.019998).  Saving model ...\n",
      "Epoch number:23,Current loss:0.1325,Current accuracy:0.9800\n",
      "\n",
      "Validation loss decreased (0.019998 --> 0.019126).  Saving model ...\n",
      "Epoch number:24,Current loss:0.1155,Current accuracy:0.9809\n",
      "\n",
      "Validation loss decreased (0.019126 --> 0.018208).  Saving model ...\n",
      "Epoch number:25,Current loss:0.1485,Current accuracy:0.9818\n",
      "\n",
      "Validation loss decreased (0.018208 --> 0.017410).  Saving model ...\n",
      "Epoch number:26,Current loss:0.1659,Current accuracy:0.9826\n",
      "\n",
      "Validation loss decreased (0.017410 --> 0.016729).  Saving model ...\n",
      "Epoch number:27,Current loss:0.1564,Current accuracy:0.9833\n",
      "\n",
      "Validation loss decreased (0.016729 --> 0.016507).  Saving model ...\n",
      "Epoch number:28,Current loss:0.1617,Current accuracy:0.9835\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:29,Current loss:0.1154,Current accuracy:0.9834\n",
      "\n",
      "Validation loss decreased (0.016507 --> 0.016271).  Saving model ...\n",
      "Epoch number:30,Current loss:0.1540,Current accuracy:0.9837\n",
      "\n",
      "Validation loss decreased (0.016271 --> 0.016108).  Saving model ...\n",
      "Epoch number:31,Current loss:0.1390,Current accuracy:0.9839\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:32,Current loss:0.0887,Current accuracy:0.9835\n",
      "\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Epoch number:33,Current loss:0.1070,Current accuracy:0.9838\n",
      "\n",
      "Validation loss decreased (0.016108 --> 0.016049).  Saving model ...\n",
      "Epoch number:34,Current loss:0.1268,Current accuracy:0.9840\n",
      "\n",
      "Validation loss decreased (0.016049 --> 0.014866).  Saving model ...\n",
      "Epoch number:35,Current loss:0.1281,Current accuracy:0.9851\n",
      "\n",
      "Validation loss decreased (0.014866 --> 0.014644).  Saving model ...\n",
      "Epoch number:36,Current loss:0.1077,Current accuracy:0.9854\n",
      "\n",
      "Validation loss decreased (0.014644 --> 0.014496).  Saving model ...\n",
      "Epoch number:37,Current loss:0.1106,Current accuracy:0.9855\n",
      "\n",
      "Validation loss decreased (0.014496 --> 0.013919).  Saving model ...\n",
      "Epoch number:38,Current loss:0.1143,Current accuracy:0.9861\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:39,Current loss:0.1139,Current accuracy:0.9858\n",
      "\n",
      "Validation loss decreased (0.013919 --> 0.013904).  Saving model ...\n",
      "Epoch number:40,Current loss:0.0857,Current accuracy:0.9861\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:41,Current loss:0.0946,Current accuracy:0.9859\n",
      "\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Epoch number:42,Current loss:0.0890,Current accuracy:0.9858\n",
      "\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Epoch number:43,Current loss:0.1277,Current accuracy:0.9859\n",
      "\n",
      "Validation loss decreased (0.013904 --> 0.013386).  Saving model ...\n",
      "Epoch number:44,Current loss:0.1445,Current accuracy:0.9866\n",
      "\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Epoch number:45,Current loss:0.1154,Current accuracy:0.9866\n",
      "\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Epoch number:46,Current loss:0.0739,Current accuracy:0.9863\n",
      "\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Epoch number:47,Current loss:0.0973,Current accuracy:0.9856\n",
      "\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Epoch number:48,Current loss:0.0821,Current accuracy:0.9853\n",
      "\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Epoch number:49,Current loss:0.0917,Current accuracy:0.9850\n",
      "\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Epoch number:50,Current loss:0.0988,Current accuracy:0.9856\n",
      "\n",
      "EarlyStopping counter: 7 out of 50\n",
      "Epoch number:51,Current loss:0.0711,Current accuracy:0.9856\n",
      "\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Epoch number:52,Current loss:0.0885,Current accuracy:0.9861\n",
      "\n",
      "EarlyStopping counter: 9 out of 50\n",
      "Epoch number:53,Current loss:0.0821,Current accuracy:0.9861\n",
      "\n",
      "EarlyStopping counter: 10 out of 50\n",
      "Epoch number:54,Current loss:0.0640,Current accuracy:0.9858\n",
      "\n",
      "EarlyStopping counter: 11 out of 50\n",
      "Epoch number:55,Current loss:0.0684,Current accuracy:0.9858\n",
      "\n",
      "EarlyStopping counter: 12 out of 50\n",
      "Epoch number:56,Current loss:0.0485,Current accuracy:0.9854\n",
      "\n",
      "EarlyStopping counter: 13 out of 50\n",
      "Epoch number:57,Current loss:0.0881,Current accuracy:0.9851\n",
      "\n",
      "EarlyStopping counter: 14 out of 50\n",
      "Epoch number:58,Current loss:0.0667,Current accuracy:0.9844\n",
      "\n",
      "EarlyStopping counter: 15 out of 50\n",
      "Epoch number:59,Current loss:0.0927,Current accuracy:0.9846\n",
      "\n",
      "EarlyStopping counter: 16 out of 50\n",
      "Epoch number:60,Current loss:0.0778,Current accuracy:0.9844\n",
      "\n",
      "EarlyStopping counter: 17 out of 50\n",
      "Epoch number:61,Current loss:0.0491,Current accuracy:0.9841\n",
      "\n",
      "EarlyStopping counter: 18 out of 50\n",
      "Epoch number:62,Current loss:0.0487,Current accuracy:0.9842\n",
      "\n",
      "EarlyStopping counter: 19 out of 50\n",
      "Epoch number:63,Current loss:0.0560,Current accuracy:0.9844\n",
      "\n",
      "EarlyStopping counter: 20 out of 50\n",
      "Epoch number:64,Current loss:0.0812,Current accuracy:0.9842\n",
      "\n",
      "EarlyStopping counter: 21 out of 50\n",
      "Epoch number:65,Current loss:0.0682,Current accuracy:0.9843\n",
      "\n",
      "EarlyStopping counter: 22 out of 50\n",
      "Epoch number:66,Current loss:0.0539,Current accuracy:0.9846\n",
      "\n",
      "EarlyStopping counter: 23 out of 50\n",
      "Epoch number:67,Current loss:0.0583,Current accuracy:0.9850\n",
      "\n",
      "EarlyStopping counter: 24 out of 50\n",
      "Epoch number:68,Current loss:0.0804,Current accuracy:0.9851\n",
      "\n",
      "EarlyStopping counter: 25 out of 50\n",
      "Epoch number:69,Current loss:0.0636,Current accuracy:0.9851\n",
      "\n",
      "EarlyStopping counter: 26 out of 50\n",
      "Epoch number:70,Current loss:0.0415,Current accuracy:0.9847\n",
      "\n",
      "EarlyStopping counter: 27 out of 50\n",
      "Epoch number:71,Current loss:0.0536,Current accuracy:0.9850\n",
      "\n",
      "EarlyStopping counter: 28 out of 50\n",
      "Epoch number:72,Current loss:0.0505,Current accuracy:0.9846\n",
      "\n",
      "EarlyStopping counter: 29 out of 50\n",
      "Epoch number:73,Current loss:0.1053,Current accuracy:0.9855\n",
      "\n",
      "EarlyStopping counter: 30 out of 50\n",
      "Epoch number:74,Current loss:0.0626,Current accuracy:0.9851\n",
      "\n",
      "EarlyStopping counter: 31 out of 50\n",
      "Epoch number:75,Current loss:0.0376,Current accuracy:0.9848\n",
      "\n",
      "EarlyStopping counter: 32 out of 50\n",
      "Epoch number:76,Current loss:0.0429,Current accuracy:0.9848\n",
      "\n",
      "EarlyStopping counter: 33 out of 50\n",
      "Epoch number:77,Current loss:0.0643,Current accuracy:0.9843\n",
      "\n",
      "EarlyStopping counter: 34 out of 50\n",
      "Epoch number:78,Current loss:0.0537,Current accuracy:0.9837\n",
      "\n",
      "EarlyStopping counter: 35 out of 50\n",
      "Epoch number:79,Current loss:0.0522,Current accuracy:0.9842\n",
      "\n",
      "EarlyStopping counter: 36 out of 50\n",
      "Epoch number:80,Current loss:0.0525,Current accuracy:0.9836\n",
      "\n",
      "EarlyStopping counter: 37 out of 50\n",
      "Epoch number:81,Current loss:0.0470,Current accuracy:0.9836\n",
      "\n",
      "EarlyStopping counter: 38 out of 50\n",
      "Epoch number:82,Current loss:0.0500,Current accuracy:0.9832\n",
      "\n",
      "EarlyStopping counter: 39 out of 50\n",
      "Epoch number:83,Current loss:0.0843,Current accuracy:0.9824\n",
      "\n",
      "EarlyStopping counter: 40 out of 50\n",
      "Epoch number:84,Current loss:0.0468,Current accuracy:0.9824\n",
      "\n",
      "EarlyStopping counter: 41 out of 50\n",
      "Epoch number:85,Current loss:0.0720,Current accuracy:0.9825\n",
      "\n",
      "EarlyStopping counter: 42 out of 50\n",
      "Epoch number:86,Current loss:0.0475,Current accuracy:0.9836\n",
      "\n",
      "EarlyStopping counter: 43 out of 50\n",
      "Epoch number:87,Current loss:0.0717,Current accuracy:0.9840\n",
      "\n",
      "EarlyStopping counter: 44 out of 50\n",
      "Epoch number:88,Current loss:0.0678,Current accuracy:0.9833\n",
      "\n",
      "EarlyStopping counter: 45 out of 50\n",
      "Epoch number:89,Current loss:0.0502,Current accuracy:0.9837\n",
      "\n",
      "EarlyStopping counter: 46 out of 50\n",
      "Epoch number:90,Current loss:0.0323,Current accuracy:0.9834\n",
      "\n",
      "EarlyStopping counter: 47 out of 50\n",
      "Epoch number:91,Current loss:0.0412,Current accuracy:0.9826\n",
      "\n",
      "EarlyStopping counter: 48 out of 50\n",
      "Epoch number:92,Current loss:0.0635,Current accuracy:0.9820\n",
      "\n",
      "EarlyStopping counter: 49 out of 50\n",
      "Epoch number:93,Current loss:0.0475,Current accuracy:0.9817\n",
      "\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model = MulitiPrototypicalNet3(X_train.shape[1],2, 24,)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.fit(X_train,y_train,X_valid,y_valid,optimizer,criterion,50,500)\n",
    "pre_Y, prob_Y = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0169ce99-b880-4f81-9baf-5a761faf4098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:   0.9578414839797639\n",
      "auc:   0.9866136141762565\n"
     ]
    }
   ],
   "source": [
    "final_model2 = torch.load(\"./finish_model_2.pkl\")\n",
    "pre_valid_y_model2, prob_valid_y_model2 = final_model2.predict(X_valid)\n",
    "acc = accuracy_score(y_valid, pre_valid_y_model2)\n",
    "auc = roc_auc_score(y_valid,prob_valid_y_model2)\n",
    "print('acc:   ' + str(acc))\n",
    "print('auc:   ' + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c461446-ed09-432a-9e7f-c8f25d670e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578414839797639"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.3, stratify=y,random_state=56)\n",
    "p2_ss = joblib.load(\"p2_ss.pkl\")\n",
    "pn_model2 = torch.load(\"./finish_model_2.pkl\")\n",
    "X_valid = p2_ss.transform(X_valid)\n",
    "accuracy_score(pn_model2.predict(X_valid)[0],y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f8ca3-ff1e-4591-81bb-87cd7d5c0fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "045c1585-0f45-4fe1-9646-347efa7e8061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank,s = miv(final_model2,X_train)\n",
    "# print(rank)\n",
    "# print(s)\n",
    "f_importance = pd.DataFrame({\"feature\": molecular_des_corr_del.columns,\"importance\": s.detach().numpy()})\n",
    "f_importance = f_importance.sort_values(by=\"importance\", ascending=False)\n",
    "# print(f_importance)\n",
    "f_importance = f_importance[:10]\n",
    "p = sns.barplot(x=\"importance\", y=\"feature\", data=f_importance,\n",
    "            order=f_importance[\"feature\"],orient=\"h\",palette=sns.color_palette(\"tab10\", 10),)\n",
    "p.set_title('CYP3A4 Feature importance')\n",
    "bar_fig = p.get_figure()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc62251c-03fb-4626-b428-34b2d9426616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nAcid</th>\n",
       "      <th>ALogP</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>AMR</th>\n",
       "      <th>apol</th>\n",
       "      <th>naAromAtom</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>nHeavyAtom</th>\n",
       "      <th>nH</th>\n",
       "      <th>...</th>\n",
       "      <th>MW</th>\n",
       "      <th>WTPT-1</th>\n",
       "      <th>WTPT-2</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>WPOL</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMILES</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H]4O[C@H]3C(=C4c5ccc(O)cc5)c6ccc(O)cc6)cc2)c1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.8193</td>\n",
       "      <td>3.309852</td>\n",
       "      <td>177.6817</td>\n",
       "      <td>89.159790</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>73</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>598.166139</td>\n",
       "      <td>88.708522</td>\n",
       "      <td>2.062989</td>\n",
       "      <td>25.464529</td>\n",
       "      <td>21.942236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7421</td>\n",
       "      <td>70</td>\n",
       "      <td>2.526</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.7289</td>\n",
       "      <td>7.446895</td>\n",
       "      <td>125.0445</td>\n",
       "      <td>60.543860</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>384.136159</td>\n",
       "      <td>59.883849</td>\n",
       "      <td>2.064960</td>\n",
       "      <td>10.441277</td>\n",
       "      <td>10.441277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>49</td>\n",
       "      <td>3.681</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=O)O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.2303</td>\n",
       "      <td>4.974238</td>\n",
       "      <td>131.6880</td>\n",
       "      <td>64.439446</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>414.146724</td>\n",
       "      <td>63.762531</td>\n",
       "      <td>2.056856</td>\n",
       "      <td>13.254618</td>\n",
       "      <td>13.254618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2661</td>\n",
       "      <td>53</td>\n",
       "      <td>3.710</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.6387</td>\n",
       "      <td>6.962738</td>\n",
       "      <td>125.1723</td>\n",
       "      <td>60.434067</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>402.126737</td>\n",
       "      <td>61.734159</td>\n",
       "      <td>2.057805</td>\n",
       "      <td>12.992047</td>\n",
       "      <td>10.440839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2424</td>\n",
       "      <td>51</td>\n",
       "      <td>3.586</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.3834</td>\n",
       "      <td>11.447396</td>\n",
       "      <td>131.3467</td>\n",
       "      <td>62.532067</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>418.103894</td>\n",
       "      <td>61.734159</td>\n",
       "      <td>2.057805</td>\n",
       "      <td>12.992047</td>\n",
       "      <td>7.310754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2424</td>\n",
       "      <td>51</td>\n",
       "      <td>3.978</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 729 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    nAcid   ALogP     ALogp2  \\\n",
       "SMILES                                                                         \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...      0  1.8193   3.309852   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4      1  2.7289   7.446895   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...      1  2.2303   4.974238   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...      1  2.6387   6.962738   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...      1  3.3834  11.447396   \n",
       "\n",
       "                                                         AMR       apol  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  177.6817  89.159790   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  125.0445  60.543860   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  131.6880  64.439446   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  125.1723  60.434067   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  131.3467  62.532067   \n",
       "\n",
       "                                                    naAromAtom  nAromBond  \\\n",
       "SMILES                                                                      \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...          24         24   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4          18         18   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...          18         18   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...          18         18   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...          18         18   \n",
       "\n",
       "                                                    nAtom  nHeavyAtom  nH  \\\n",
       "SMILES                                                                      \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...     73          43  30   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4     49          29  20   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...     53          31  22   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...     49          30  19   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...     49          30  19   \n",
       "\n",
       "                                                    ...          MW  \\\n",
       "SMILES                                              ...               \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  ...  598.166139   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  ...  384.136159   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  ...  414.146724   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  ...  402.126737   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  ...  418.103894   \n",
       "\n",
       "                                                       WTPT-1    WTPT-2  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  88.708522  2.062989   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  59.883849  2.064960   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  63.762531  2.056856   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  61.734159  2.057805   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  61.734159  2.057805   \n",
       "\n",
       "                                                       WTPT-3     WTPT-4  \\\n",
       "SMILES                                                                     \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  25.464529  21.942236   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  10.441277  10.441277   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  13.254618  13.254618   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  12.992047  10.440839   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  12.992047   7.310754   \n",
       "\n",
       "                                                    WTPT-5  WPATH  WPOL  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...     0.0   7421    70   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4     0.0   2217    49   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...     0.0   2661    53   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...     0.0   2424    51   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...     0.0   2424    51   \n",
       "\n",
       "                                                    XLogP  Zagreb  \n",
       "SMILES                                                             \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  2.526     236  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  3.681     152  \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  3.710     162  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  3.586     158  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  3.978     158  \n",
       "\n",
       "[5 rows x 729 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecular_test = pd.read_excel('../../data/Molecular_Descriptor.xlsx',sheet_name=\"test\",engine='openpyxl',index_col=0,)\n",
    "molecular_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02b58a5d-f742-4add-ba71-bf8bd55a097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "final_test_coulmns = molecular_des_corr_del.columns.tolist()\n",
    "final_test = molecular_test.loc[:,final_test_coulmns].values\n",
    "p2_ss = joblib.load(\"p2_ss.pkl\")\n",
    "pn_model2 = torch.load(\"./finish_model_2.pkl\")\n",
    "final_test = p2_ss.transform(final_test)\n",
    "for i in pn_model2.predict(final_test)[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb873511-9c34-4ddf-af88-d12e157a2eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36352a49-2dfc-42b8-bb1a-c02d7a55cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE,SMOTE,ADASYN \n",
    "X_train_os, y_train_os = ADASYN (sampling_strategy='minority',n_neighbors=11).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9b3defe-0984-430b-8161-20af9d95a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number:0,Current loss:0.0132\n",
      "\n",
      "Epoch number:1,Current loss:0.0201\n",
      "\n",
      "Epoch number:2,Current loss:0.0027\n",
      "\n",
      "Epoch number:3,Current loss:0.0122\n",
      "\n",
      "Epoch number:4,Current loss:0.0179\n",
      "\n",
      "Epoch number:5,Current loss:0.0152\n",
      "\n",
      "Epoch number:6,Current loss:0.0127\n",
      "\n",
      "Epoch number:7,Current loss:0.0104\n",
      "\n",
      "Epoch number:8,Current loss:0.0140\n",
      "\n",
      "Epoch number:9,Current loss:0.0213\n",
      "\n",
      "Epoch number:10,Current loss:0.0067\n",
      "\n",
      "Epoch number:11,Current loss:0.0114\n",
      "\n",
      "Epoch number:12,Current loss:0.0140\n",
      "\n",
      "Epoch number:13,Current loss:0.0194\n",
      "\n",
      "Epoch number:14,Current loss:0.0293\n",
      "\n",
      "Epoch number:15,Current loss:0.0198\n",
      "\n",
      "Epoch number:16,Current loss:0.0041\n",
      "\n",
      "Epoch number:17,Current loss:0.0030\n",
      "\n",
      "Epoch number:18,Current loss:0.0046\n",
      "\n",
      "Epoch number:19,Current loss:0.0070\n",
      "\n",
      "Epoch number:20,Current loss:0.0250\n",
      "\n",
      "Epoch number:21,Current loss:0.0194\n",
      "\n",
      "Epoch number:22,Current loss:0.0118\n",
      "\n",
      "Epoch number:23,Current loss:0.0218\n",
      "\n",
      "Epoch number:24,Current loss:0.0067\n",
      "\n",
      "Epoch number:25,Current loss:0.0203\n",
      "\n",
      "Epoch number:26,Current loss:0.0048\n",
      "\n",
      "Epoch number:27,Current loss:0.0041\n",
      "\n",
      "Epoch number:28,Current loss:0.0228\n",
      "\n",
      "Epoch number:29,Current loss:0.0216\n",
      "\n",
      "Epoch number:30,Current loss:0.0194\n",
      "\n",
      "Epoch number:31,Current loss:0.0123\n",
      "\n",
      "Epoch number:32,Current loss:0.0236\n",
      "\n",
      "Epoch number:33,Current loss:0.0117\n",
      "\n",
      "Epoch number:34,Current loss:0.0104\n",
      "\n",
      "Epoch number:35,Current loss:0.0184\n",
      "\n",
      "Epoch number:36,Current loss:0.0146\n",
      "\n",
      "Epoch number:37,Current loss:0.0053\n",
      "\n",
      "Epoch number:38,Current loss:0.0168\n",
      "\n",
      "Epoch number:39,Current loss:0.0170\n",
      "\n",
      "Epoch number:40,Current loss:0.0047\n",
      "\n",
      "Epoch number:41,Current loss:0.0081\n",
      "\n",
      "Epoch number:42,Current loss:0.0065\n",
      "\n",
      "Epoch number:43,Current loss:0.0265\n",
      "\n",
      "Epoch number:44,Current loss:0.0294\n",
      "\n",
      "Epoch number:45,Current loss:0.0182\n",
      "\n",
      "Epoch number:46,Current loss:0.0278\n",
      "\n",
      "Epoch number:47,Current loss:0.0213\n",
      "\n",
      "Epoch number:48,Current loss:0.0267\n",
      "\n",
      "Epoch number:49,Current loss:0.0191\n",
      "\n",
      "Epoch number:50,Current loss:0.0140\n",
      "\n",
      "Epoch number:51,Current loss:0.0165\n",
      "\n",
      "Epoch number:52,Current loss:0.0104\n",
      "\n",
      "Epoch number:53,Current loss:0.0063\n",
      "\n",
      "Epoch number:54,Current loss:0.0257\n",
      "\n",
      "Epoch number:55,Current loss:0.0183\n",
      "\n",
      "Epoch number:56,Current loss:0.0096\n",
      "\n",
      "Epoch number:57,Current loss:0.0133\n",
      "\n",
      "Epoch number:58,Current loss:0.0109\n",
      "\n",
      "Epoch number:59,Current loss:0.0109\n",
      "\n",
      "Epoch number:60,Current loss:0.0101\n",
      "\n",
      "Epoch number:61,Current loss:0.0319\n",
      "\n",
      "Epoch number:62,Current loss:0.0331\n",
      "\n",
      "Epoch number:63,Current loss:0.0055\n",
      "\n",
      "Epoch number:64,Current loss:0.0137\n",
      "\n",
      "Epoch number:65,Current loss:0.0175\n",
      "\n",
      "Epoch number:66,Current loss:0.0115\n",
      "\n",
      "Epoch number:67,Current loss:0.0109\n",
      "\n",
      "Epoch number:68,Current loss:0.0116\n",
      "\n",
      "Epoch number:69,Current loss:0.0146\n",
      "\n",
      "Epoch number:70,Current loss:0.0043\n",
      "\n",
      "Epoch number:71,Current loss:0.0157\n",
      "\n",
      "Epoch number:72,Current loss:0.0103\n",
      "\n",
      "Epoch number:73,Current loss:0.0123\n",
      "\n",
      "Epoch number:74,Current loss:0.0242\n",
      "\n",
      "Epoch number:75,Current loss:0.0073\n",
      "\n",
      "Epoch number:76,Current loss:0.0059\n",
      "\n",
      "Epoch number:77,Current loss:0.0135\n",
      "\n",
      "Epoch number:78,Current loss:0.0176\n",
      "\n",
      "Epoch number:79,Current loss:0.0179\n",
      "\n",
      "Epoch number:80,Current loss:0.0097\n",
      "\n",
      "Epoch number:81,Current loss:0.0096\n",
      "\n",
      "Epoch number:82,Current loss:0.0192\n",
      "\n",
      "Epoch number:83,Current loss:0.0104\n",
      "\n",
      "Epoch number:84,Current loss:0.0155\n",
      "\n",
      "Epoch number:85,Current loss:0.0126\n",
      "\n",
      "Epoch number:86,Current loss:0.0072\n",
      "\n",
      "Epoch number:87,Current loss:0.0082\n",
      "\n",
      "Epoch number:88,Current loss:0.0397\n",
      "\n",
      "Epoch number:89,Current loss:0.0135\n",
      "\n",
      "Epoch number:90,Current loss:0.0076\n",
      "\n",
      "Epoch number:91,Current loss:0.0140\n",
      "\n",
      "Epoch number:92,Current loss:0.0126\n",
      "\n",
      "Epoch number:93,Current loss:0.0087\n",
      "\n",
      "Epoch number:94,Current loss:0.0076\n",
      "\n",
      "Epoch number:95,Current loss:0.0146\n",
      "\n",
      "Epoch number:96,Current loss:0.0095\n",
      "\n",
      "Epoch number:97,Current loss:0.0057\n",
      "\n",
      "Epoch number:98,Current loss:0.0082\n",
      "\n",
      "Epoch number:99,Current loss:0.0121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = MulitiPrototypicalNet3(X_train.shape[1],2, 24)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001, weight_decay=0.001)\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "model.fit(X_train_os,y_train_os,optimizer,criterion,100)\n",
    "pre_Y, prob_Y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cf7477d-268e-49fd-90a2-b54db53babdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9494097807757167"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pre_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2130ed97-eb80-4756-a931-9bc29b71416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9806008342454812"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,prob_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500935db-2e08-491d-b91b-5873d4e7c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c2c4d-7cdc-4bf9-a8b8-81907b8605ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b32b6de1-016c-4798-80ac-d39ad93f8295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nAcid</th>\n",
       "      <th>ALogP</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>AMR</th>\n",
       "      <th>apol</th>\n",
       "      <th>naAromAtom</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>nHeavyAtom</th>\n",
       "      <th>nH</th>\n",
       "      <th>...</th>\n",
       "      <th>MW</th>\n",
       "      <th>WTPT-1</th>\n",
       "      <th>WTPT-2</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>WPOL</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMILES</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H]4O[C@H]3C(=C4c5ccc(O)cc5)c6ccc(O)cc6)cc2)c1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.8193</td>\n",
       "      <td>3.309852</td>\n",
       "      <td>177.6817</td>\n",
       "      <td>89.159790</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>73</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>598.166139</td>\n",
       "      <td>88.708522</td>\n",
       "      <td>2.062989</td>\n",
       "      <td>25.464529</td>\n",
       "      <td>21.942236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7421</td>\n",
       "      <td>70</td>\n",
       "      <td>2.526</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.7289</td>\n",
       "      <td>7.446895</td>\n",
       "      <td>125.0445</td>\n",
       "      <td>60.543860</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>384.136159</td>\n",
       "      <td>59.883849</td>\n",
       "      <td>2.064960</td>\n",
       "      <td>10.441277</td>\n",
       "      <td>10.441277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>49</td>\n",
       "      <td>3.681</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=O)O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.2303</td>\n",
       "      <td>4.974238</td>\n",
       "      <td>131.6880</td>\n",
       "      <td>64.439446</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>414.146724</td>\n",
       "      <td>63.762531</td>\n",
       "      <td>2.056856</td>\n",
       "      <td>13.254618</td>\n",
       "      <td>13.254618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2661</td>\n",
       "      <td>53</td>\n",
       "      <td>3.710</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.6387</td>\n",
       "      <td>6.962738</td>\n",
       "      <td>125.1723</td>\n",
       "      <td>60.434067</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>402.126737</td>\n",
       "      <td>61.734159</td>\n",
       "      <td>2.057805</td>\n",
       "      <td>12.992047</td>\n",
       "      <td>10.440839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2424</td>\n",
       "      <td>51</td>\n",
       "      <td>3.586</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc(O)cc4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.3834</td>\n",
       "      <td>11.447396</td>\n",
       "      <td>131.3467</td>\n",
       "      <td>62.532067</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>418.103894</td>\n",
       "      <td>61.734159</td>\n",
       "      <td>2.057805</td>\n",
       "      <td>12.992047</td>\n",
       "      <td>7.310754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2424</td>\n",
       "      <td>51</td>\n",
       "      <td>3.978</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 729 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    nAcid   ALogP     ALogp2  \\\n",
       "SMILES                                                                         \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...      0  1.8193   3.309852   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4      1  2.7289   7.446895   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...      1  2.2303   4.974238   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...      1  2.6387   6.962738   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...      1  3.3834  11.447396   \n",
       "\n",
       "                                                         AMR       apol  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  177.6817  89.159790   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  125.0445  60.543860   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  131.6880  64.439446   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  125.1723  60.434067   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  131.3467  62.532067   \n",
       "\n",
       "                                                    naAromAtom  nAromBond  \\\n",
       "SMILES                                                                      \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...          24         24   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4          18         18   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...          18         18   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...          18         18   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...          18         18   \n",
       "\n",
       "                                                    nAtom  nHeavyAtom  nH  \\\n",
       "SMILES                                                                      \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...     73          43  30   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4     49          29  20   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...     53          31  22   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...     49          30  19   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...     49          30  19   \n",
       "\n",
       "                                                    ...          MW  \\\n",
       "SMILES                                              ...               \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  ...  598.166139   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  ...  384.136159   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  ...  414.146724   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  ...  402.126737   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  ...  418.103894   \n",
       "\n",
       "                                                       WTPT-1    WTPT-2  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  88.708522  2.062989   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  59.883849  2.064960   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  63.762531  2.056856   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  61.734159  2.057805   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  61.734159  2.057805   \n",
       "\n",
       "                                                       WTPT-3     WTPT-4  \\\n",
       "SMILES                                                                     \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  25.464529  21.942236   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  10.441277  10.441277   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  13.254618  13.254618   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  12.992047  10.440839   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  12.992047   7.310754   \n",
       "\n",
       "                                                    WTPT-5  WPATH  WPOL  \\\n",
       "SMILES                                                                    \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...     0.0   7421    70   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4     0.0   2217    49   \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...     0.0   2661    53   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...     0.0   2424    51   \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...     0.0   2424    51   \n",
       "\n",
       "                                                    XLogP  Zagreb  \n",
       "SMILES                                                             \n",
       "COc1cc(OC)cc(\\C=C\\c2ccc(OS(=O)(=O)[C@@H]3C[C@@H...  2.526     236  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3ccccc23)c4ccc(O)cc4  3.681     152  \n",
       "COc1ccc2C(=C(CCOc2c1)c3ccc(O)cc3)c4ccc(\\C=C\\C(=...  3.710     162  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCOc3cc(F)ccc23)c4ccc...  3.586     158  \n",
       "OC(=O)\\C=C\\c1ccc(cc1)C2=C(CCSc3cc(F)ccc23)c4ccc...  3.978     158  \n",
       "\n",
       "[5 rows x 729 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecular_test = pd.read_excel('../../data/Molecular_Descriptor.xlsx',sheet_name=\"test\",engine='openpyxl',index_col=0,)\n",
    "molecular_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "21cc2373-1b4f-4d0f-aeb4-a0cd41c27c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = molecular_test.loc[:,final_test_coulmns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "36da7229-b8f2-4424-9012-d461b9b32a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 132)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "230724be-bfc3-4eaa-8118-816d4128c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_coulmns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92480fc-bf25-416a-9b3a-06ef1f5f067c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3cde76-f3e8-4c5a-b11a-40ade5b3422c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e758ad9-3506-435a-931a-1f4a9125bbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b13f9-0d3b-4954-8f35-99beb56d9724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
